{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d319152",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"content/CBOW.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3b1aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \\n\\nFurther, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission â€“transmission of the virus before the appearance of symptoms â€“ is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \\n\\nThe reproductive number â€“ the number of secondary infections generated from one infected individual â€“ is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.  '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156d404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb467c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = file_contents.split('.')\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Generate context-target pairs for training\n",
    "window_size = 3\n",
    "tokenized_sentences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "data, labels = [], []\n",
    "for sentence in tokenized_sentences:\n",
    "    for i, target_word in enumerate(sentence):\n",
    "        context = [\n",
    "            sentence[j] for j in range(i - window_size, i + window_size + 1)\n",
    "            if j != i and 0 <= j < len(sentence)\n",
    "        ]\n",
    "        data.append(context)\n",
    "        labels.append(target_word)\n",
    "\n",
    "# Convert data and labels to numpy arrays\n",
    "data = pad_sequences(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f21a02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential([\n",
    "#     layers.Embedding(input_dim=total_words, output_dim=50, input_length=window_size * 2),\n",
    "#     layers.GlobalAveragePooling1D(),\n",
    "#     layers.Dense(total_words, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b483662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 6, 50)             5150      \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 50)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 103)               5253      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10403 (40.64 KB)\n",
      "Trainable params: 10403 (40.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = total_words, output_dim = 50, input_length = window_size*2))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(total_words, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68139dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 4s 8ms/step - loss: 4.6341 - accuracy: 0.0051 \n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.6248 - accuracy: 0.0455\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.6170 - accuracy: 0.1061\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.6094 - accuracy: 0.1515\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.6015 - accuracy: 0.1818\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.5936 - accuracy: 0.1768\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.5851 - accuracy: 0.1818\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.5759 - accuracy: 0.1970\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 4.5660 - accuracy: 0.1970\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.5552 - accuracy: 0.2121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cc6a0f7750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(data, labels, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2bd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014c9104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'influenza': ['influenza', '19', 'for', 'driver', 'successive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "target_word = 'influenza'\n",
    "target_embedding = word_embeddings[tokenizer.word_index[target_word]]\n",
    "\n",
    "similarities = cosine_similarity(target_embedding.reshape(1, -1), word_embeddings)[0]\n",
    "most_similar_indices = similarities.argsort()[-5:][::-1]\n",
    "    \n",
    "most_similar_words = [word for word, idx in tokenizer.word_index.items() if idx in most_similar_indices]\n",
    "\n",
    "print(f\"Most similar words to '{target_word}': {most_similar_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da161327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075f802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2d797b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262e85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43432cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1585674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a2e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df023529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6669d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
